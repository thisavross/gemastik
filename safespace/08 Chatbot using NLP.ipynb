{"cells":[{"cell_type":"markdown","metadata":{"id":"HalGjSjJNRaw"},"source":["Problem Statement:\n","A company wants to do chatbot that working 24/7 can serve customer on their Whatsapp chat.\n","\n","In the dataset, we have words, classes and documents\n","\n","Letâ€™s begin:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6467,"status":"ok","timestamp":1700729233731,"user":{"displayName":"Hasanul Fahmi","userId":"03456566594177669163"},"user_tz":-420},"id":"nMcYmPQF3krn","outputId":"fb04d859-9c07-439f-9ef1-1912a662dd41"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\xynpy\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Libraries needed for Tensorflow processing\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["# Libraries needed for NLP\n","import nltk\n","nltk.download('punkt')\n","from nltk.stem import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","# Libraries needed for Tensorflow processing\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":35},"id":"zitZRhjq9Vqu"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-28ee39dc-43c8-4019-9b5e-cb9671536297\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-28ee39dc-43c8-4019-9b5e-cb9671536297\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-fde790dc6427>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load the intents.json file from your local device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["#load the intents.json file from your local device\n","from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sBEuh9TEGBo7"},"outputs":[],"source":["# import our chat-bot intents file\n","with open('intents.json') as json_data:\n","    intents = json.load(json_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mpFsVWPKGKbI"},"outputs":[],"source":["intents"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jUNlDhkSGVL1"},"outputs":[],"source":["words = []\n","classes = []\n","documents = []\n","ignore = ['?']\n","# loop through each sentence in the intent's patterns\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        # tokenize each and every word in the sentence\n","        w = nltk.word_tokenize(pattern)\n","        # add word to the words list\n","        words.extend(w)\n","        # add word(s) to documents\n","        documents.append((w, intent['tag']))\n","        # add tags to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GO7b9xTwHJMJ"},"outputs":[],"source":["# Perform stemming and lower each word as well as remove duplicates\n","words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n","words = sorted(list(set(words)))\n","\n","# remove duplicate classes\n","classes = sorted(list(set(classes)))\n","\n","print (len(documents), \"documents\")\n","print (len(classes), \"classes\", classes)\n","print (len(words), \"unique stemmed words\", words)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vziuGlP1Iq-P"},"outputs":[],"source":["# create training data\n","training = []\n","output = []\n","# create an empty array for output\n","output_empty = [0] * len(classes)\n","\n","# create training set, bag of words for each sentence\n","for doc in documents:\n","    # initialize bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # stemming each word\n","    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n","    # create bag of words array\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # output is '1' for current tag and '0' for rest of other tags\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n","\n","# shuffling features and turning it into np.array\n","random.shuffle(training)\n","training = np.array(training)\n","\n","# creating training lists\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"42dWr6eG_xs0"},"outputs":[],"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(10,input_shape=(len(train_x[0]),)))\n","model.add(tf.keras.layers.Dense(10))\n","model.add(tf.keras.layers.Dense(len(train_y[0]), activation='softmax'))\n","model.compile(tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"T8fPUE4kBID7"},"outputs":[],"source":["model.fit(np.array(train_x), np.array(train_y), epochs=1000, batch_size=8, verbose=1)\n","model.save(\"model.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ha2RGmK1Zz5l"},"outputs":[],"source":["import pickle\n","pickle.dump( {'words':words, 'classes':classes}, open( \"training_data\", \"wb\" ) )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jIrMS64WCVhm"},"outputs":[],"source":["from keras.models import load_model\n","model = load_model(\"model.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ux9WbDZvbAzf"},"outputs":[],"source":["# restoring all the data structures\n","data = pickle.load( open( \"training_data\", \"rb\" ) )\n","words = data['words']\n","classes = data['classes']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ms17AFyEbEjt"},"outputs":[],"source":["with open('intents.json') as json_data:\n","    intents = json.load(json_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VB27k_vQbhu4"},"outputs":[],"source":["def clean_up_sentence(sentence):\n","    # tokenizing the pattern\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # stemming each word\n","    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words):\n","    # tokenizing the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # generating bag of words\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                bag[i] = 1\n","    bag=np.array(bag)\n","    return(bag)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3lToEtkTb5Pr"},"outputs":[],"source":["ERROR_THRESHOLD = 0.30\n","def classify(sentence):\n","    # generate probabilities from the model\n","    bag = bow(sentence, words)\n","    results = model.predict(np.array([bag]))\n","    # filter out predictions below a threshold\n","    results = [[i,r] for i,r in enumerate(results[0]) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append((classes[r[0]], r[1]))\n","    # return tuple of intent and probability\n","    return return_list\n","\n","def response(sentence):\n","    results = classify(sentence)\n","    # if we have a classification then find the matching intent tag\n","    if results:\n","        # loop as long as there are matches to process\n","        while results:\n","            for i in intents['intents']:\n","                # find a tag matching the first result\n","                if i['tag'] == results[0][0]:\n","                    # a random response from the intent\n","                    return print(random.choice(i['responses']))\n","\n","            results.pop(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"executionInfo":{"elapsed":19,"status":"error","timestamp":1685977979559,"user":{"displayName":"ANGGRAINI DYAH AYU SEKARLANGIT","userId":"16119934660741555838"},"user_tz":-420},"id":"xp7OJvpHKXuw","outputId":"915dc004-41c3-474e-f774-788f4bb44ecb"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-92273924e7c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Where are you located?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"]}],"source":["response('Where are you located?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3PNLGpl0gKCF"},"outputs":[],"source":["response('That is helpful')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wzeIGchZK2fJ"},"outputs":[],"source":["response('Bye')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kUzPSymMida8"},"outputs":[],"source":["response(\"Why are you?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"11MehCNQinZB"},"outputs":[],"source":["response((\"hye, are you die\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hq04OiLWNRbN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
